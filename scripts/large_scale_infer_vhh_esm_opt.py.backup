es (per batch):
      preprocess merged PDBs + HL FASTAs + manifest
        embed (sharded, N GPUs) -> emb_part*.h5
          annotate
            graph generation
              inject embeddings from emb_part*.h5 into graph HDF5
                cluster + predict

                Usage example:
                      python3 large_scale_infer_vhh.py \
                                  --pdb-folder input_models/ \
                                      --out processed_data/ \
                                          --heavy H --light - --antigen T \
                                              --model-path top_mse_ep37_mse2.3192e-02_treg_ydockq_b128_e100_lr2e-03.pth.tar \
                                                  --graph-batch-size 500 --num-cores 32 --dl-workers 8 \
                                                      --esm-gpus 4 --esm-toks-per-batch 12288

                                                      Notes:
                                                          - This script expects to be run inside (or with PYTHONPATH pointing to) the DeepRank-Ab repo
                                                            so that DataSet, GraphGenMP, NeuralNet_focal_EMA, EGNN, and annotate imports resolve.
                                                            """

                                                            import argparse
                                                            import js#!/usr/bin/env python3
"""
Large-scale (batched) DeepRank-Ab inference with VHH (H-only) support.

UPDATED (2026-01-31): 4-GPU sharded, scalar-only ESM embeddings
---------------------------------------------------------------
Key changes vs prior version:
- ESM model is NOT loaded per-structure.
- For each batch, we build a manifest of sequences (mol.A and mol.B), shard it across N GPUs
  (balanced by sequence length), and run N embedding workers (one per GPU).
- Each worker loads ESM once and writes scalar-per-residue embeddings to an HDF5 part file:
    embeddings/emb_part{i}.h5
  with datasets under /scalar/<label> where label is "<mol>.A" or "<mol>.B".
- Embedding injection reads from the HDF5 part files (no per-molecule .pt files).

Pipeline stagon
import logging
import os
import shutil
import subprocess
import tempfile
from dataclasses import dataclass
from pathlib import Path
from time import perf_counter
from typing import Dict, List, Optional, Tuple

import sys

SCRIPT_DIR = Path(__file__).resolve().parent          # .../DeepRank-Ab/scripts
ROOT_DIR   = SCRIPT_DIR.parent                       # .../DeepRank-Ab
SRC_DIR    = ROOT_DIR / "src"                        # .../DeepRank-Ab/src

# Ensure imports work no matter where you run from
sys.path.insert(0, str(ROOT_DIR))

import h5py
import torch
from Bio.PDB import PDBParser, PDBIO
from Bio.PDB.Structure import Structure
from Bio.PDB.Model import Model
from Bio.PDB.Chain import Chain
from Bio.PDB.Polypeptide import PPBuilder

from src.DataSet import HDF5DataSet, PreCluster
from src.GraphGenMP import GraphHDF5
from src.tools.annotate import annotate_folder_one_by_one_mp
from src.NeuralNet_focal_EMA import NeuralNet
from src.EGNN import egnn

# ESM
from esm import FastaBatchedDataset, pretrained


# ----------------------------
# Logging
# ----------------------------
log = logging.getLogger("drab-batch")
log.setLevel(logging.INFO)
_hdl = logging.StreamHandler()
_hdl.setFormatter(logging.Formatter(" [%(levelname)s] %(message)s"))
log.addHandler(_hdl)


# ----------------------------
# Config defaults
# ----------------------------
NODE_FEATURES = ["atom_type", "polarity", "bsa", "region", "embedding"]
EDGE_FEATURES = ["voro_area", "covalent", "vdw", "orientation"]

DEFAULT_TOKS_PER_BATCH = int(os.environ.get("ESM_TOKS_PER_BATCH", "12288"))
REPR_LAYERS = [33]
TRUNCATION_SEQ_LENGTH = 2500
INCLUDE = ["per_tok"]  # we only need per-token reps; we'll compute scalar-per-residue ourselves

# If you already set ESM weights via env vars, this will work fine
ESM_MODEL = os.environ.get("ESM_MODEL", "esm2_t33_650M_UR50D")


# ----------------------------
# Helpers
# ----------------------------
def is_missing_chain(x: str) -> bool:
    return (x is None) or (str(x).strip() == "") or (str(x).strip() == "-") or (str(x).strip().lower() == "none")


def chunk_list(items: List[Path], size: int):
    for i in range(0, len(items), size):
        yield items[i : i + size]


def safe_mkdir(p: Path) -> Path:
    p.mkdir(parents=True, exist_ok=True)
    return p


def split_models(pdb_path: Path, out_dir: Path) -> List[Path]:
    """Split ensemble PDB into per-model PDBs. If only one model, returns single file."""
    parser = PDBParser(QUIET=True)
    struct = parser.get_structure(pdb_path.stem, str(pdb_path))

    models = list(struct)
    is_ensemble = len(models) > 1

    io = PDBIO()
    saved: List[Path] = []
    safe_mkdir(out_dir)

    for m in models:
        mid = m.id if is_ensemble else 0
        out = out_dir / f"{pdb_path.stem}_model_{mid}.pdb"
        io.set_structure(m)
        io.save(str(out))
        saved.append(out)

    return saved


def chain_sequence_from_pdb(pdb_path: Path, chain_id: str) -> str:
    """Extract polypeptide sequence for a chain using PPBuilder (more robust than residue-name mapping)."""
    if is_missing_chain(chain_id):
        return ""
    parser = PDBParser(QUIET=True)
    struct = parser.get_structure(pdb_path.stem, str(pdb_path))
    model = struct[0]
    if chain_id not in model:
        return ""

    chain = model[chain_id]
    ppb = PPBuilder()
    peptides = ppb.build_peptides(chain)
    if not peptides:
        return ""
    # If multiple peptides (chain breaks), concatenate (matches typical DeepRank-Ab behavior)
    return "".join(str(pp.get_sequence()) for pp in peptides)


def _copy_residue(res):
    """Biopython Residue copy."""
    return res.copy()


def build_merged_structure(
    pdb_path: Path,
    heavy_chain_id: str,
    light_chain_id: str,
    antigen_chain_id: str,
    out_pdb: Path,
) -> Tuple[str, str, str]:
    """
    Create a fresh structure with two chains:
      A: Ab (H + optional L) renumbered from 1
      B: Ag (antigen) renumbered from 1

    Returns: (seqH, seqL, seqAg) from the *input* PDB chains.
    """
    parser = PDBParser(QUIET=True)
    struct = parser.get_structure(pdb_path.stem, str(pdb_path))
    model_in = struct[0]

    # sequences from original chains for FASTA creation
    seqH = chain_sequence_from_pdb(pdb_path, heavy_chain_id)
    seqL = "" if is_missing_chain(light_chain_id) else chain_sequence_from_pdb(pdb_path, light_chain_id)
    seqAg = chain_sequence_from_pdb(pdb_path, antigen_chain_id)

    if heavy_chain_id not in model_in:
        raise ValueError(f"{pdb_path.name}: heavy chain '{heavy_chain_id}' not found")
    if antigen_chain_id not in model_in:
        raise ValueError(f"{pdb_path.name}: antigen chain '{antigen_chain_id}' not found")
    if (not is_missing_chain(light_chain_id)) and (light_chain_id not in model_in):
        raise ValueError(f"{pdb_path.name}: light chain '{light_chain_id}' not found")

    # Build new structure
    s = Structure(pdb_path.stem)
    m = Model(0)
    s.add(m)

    chainA = Chain("A")
    chainB = Chain("B")
    m.add(chainA)
    m.add(chainB)

    # Helper: append residues renumbered
    def append_chain(dst_chain: Chain, src_chain_ids: List[str]):
        idx = 1
        for cid in src_chain_ids:
            if is_missing_chain(cid):
                continue
            src_chain = model_in[cid]
            for res in src_chain:
                new_res = _copy_residue(res)
                new_res.id = (" ", idx, " ")
                dst_chain.add(new_res)
                idx += 1

    # Ab chain: H then (optional) L
    append_chain(chainA, [heavy_chain_id, light_chain_id])
    # Ag chain
    append_chain(chainB, [antigen_chain_id])

    out_pdb.parent.mkdir(parents=True, exist_ok=True)
    io = PDBIO()
    io.set_structure(s)
    io.save(str(out_pdb))

    return seqH, seqL, seqAg


def write_hl_fasta(stem: str, fasta_dir: Path, seqH: str, seqL: str) -> Path:
    """Writes {stem}_HL.fasta (H and optionally L). Returns path."""
    safe_mkdir(fasta_dir)
    fasta_hl = fasta_dir / f"{stem}_HL.fasta"
    with open(fasta_hl, "w") as f:
        if seqH:
            f.write(f">{stem}.H\n{seqH}\n")
        if seqL:
            f.write(f">{stem}.L\n{seqL}\n")
    return fasta_hl


# ----------------------------
# Annotation / region JSON normalization
# ----------------------------
def correct_region_json(region_json: Path) -> None:
    """
    DeepRank-Ab annotate writes keys like "<stem>.pdb" sometimes.
    Graph generator often uses "<stem>".
    Normalize keys by stripping ".pdb" suffix.
    """
    if not region_json.is_file():
        raise FileNotFoundError(f"Missing region JSON: {region_json}")

    with open(region_json, "r") as f:
        data = json.load(f)
    new = {k.replace(".pdb", ""): v for k, v in data.items()}

    with open(region_json, "w") as f:
        json.dump(new, f, indent=2)


# ----------------------------
# Graph generation
# ----------------------------
def gen_graphs(
    pdb_dir: Path,
    outfile: Path,
    region_json: Path,
    n_cores: int,
    antigen_chainid: str = "B",
    tmp_base: Optional[Path] = None,
):
    tmpdir = Path(tempfile.mkdtemp(prefix="drab_graph_", dir=str(tmp_base) if tmp_base else None))
    try:
        GraphHDF5(
            pdb_path=str(pdb_dir),
            outfile=str(outfile),
            graph_type="atom",
            nproc=n_cores,
            tmpdir=str(tmpdir),
            use_regions=True,
            region_json=str(region_json),
            antigen_chainid=antigen_chainid,
            add_orientation=True,
            use_voro=True,
            contact_features=True,
            embedding_path=None,  # we inject ourselves below
        )
    finally:
        shutil.rmtree(tmpdir, ignore_errors=True)


# ----------------------------
# Sharded scalar-only ESM embeddings
# ----------------------------
@dataclass
class SeqRecord:
    label: str   # "<mol>.A" or "<mol>.B"
    mol: str     # "<mol>"
    chain: str   # "A" or "B"
    length: int
    sequence: str


def write_manifest_tsv(records: List[SeqRecord], out_tsv: Path) -> None:
    out_tsv.parent.mkdir(parents=True, exist_ok=True)
    with open(out_tsv, "w") as f:
        f.write("label\tmol\tchain\tlength\tsequence\n")
        for r in records:
            f.write(f"{r.label}\t{r.mol}\t{r.chain}\t{r.length}\t{r.sequence}\n")


def read_manifest_tsv(tsv: Path) -> List[SeqRecord]:
    recs: List[SeqRecord] = []
    with open(tsv, "r") as f:
        header = f.readline()
        for line in f:
            line = line.rstrip("\n")
            if not line:
                continue
            parts = line.split("\t")
            if len(parts) < 5:
                continue
            label, mol, chain, length_s, seq = parts[0], parts[1], parts[2], parts[3], parts[4]
            recs.append(SeqRecord(label=label, mol=mol, chain=chain, length=int(length_s), sequence=seq))
    return recs


def shard_records_balanced(records: List[SeqRecord], n_shards: int) -> Tuple[List[List[SeqRecord]], Dict[str, int]]:
    """
    Greedy bin-pack by length (approx token cost) to balance shards.
    Returns shards and label->shard mapping.
    """
    # cost ~ length + 2 tokens (rough; good enough for balancing)
    items = sorted(records, key=lambda r: (r.length + 2), reverse=True)
    shards: List[List[SeqRecord]] = [[] for _ in range(n_shards)]
    loads = [0 for _ in range(n_shards)]
    label_to_shard: Dict[str, int] = {}

    for r in items:
        i = min(range(n_shards), key=lambda k: loads[k])
        shards[i].append(r)
        loads[i] += (r.length + 2)
        label_to_shard[r.label] = i

    return shards, label_to_shard


def write_shard_tsv(records: List[SeqRecord], out_tsv: Path) -> None:
    out_tsv.parent.mkdir(parents=True, exist_ok=True)
    with open(out_tsv, "w") as f:
        f.write("label\tlength\tsequence\n")
        for r in records:
            f.write(f"{r.label}\t{r.length}\t{r.sequence}\n")


def shard_tsv_to_fasta(shard_tsv: Path, out_fasta: Path) -> int:
    """
    Convert shard TSV to FASTA for esm.FastaBatchedDataset.
    Returns number of records.
    """
    n = 0
    with open(shard_tsv, "r") as fin, open(out_fasta, "w") as fout:
        header = fin.readline()
        for line in fin:
            line = line.rstrip("\n")
            if not line:
                continue
            parts = line.split("\t")
            if len(parts) < 3:
                continue
            label, _len, seq = parts[0], parts[1], parts[2]
            if not seq:
                continue
            fout.write(f">{label}\n{seq}\n")
            n += 1
    return n


def validate_embedding_parts(
    shard_tsvs: List[Path],
    part_h5s: List[Path],
) -> None:
    """
    Validate that each label in shard TSV exists in corresponding HDF5 and lengths match.
    """
    if len(shard_tsvs) != len(part_h5s):
        raise ValueError("validate_embedding_parts: shard_tsvs and part_h5s length mismatch")

    for i, (stsv, ph5) in enumerate(zip(shard_tsvs, part_h5s)):
        if not ph5.is_file():
            raise FileNotFoundError(f"Missing embedding part file: {ph5}")

        expected: Dict[str, int] = {}
        with open(stsv, "r") as f:
            _ = f.readline()
            for line in f:
                line = line.rstrip("\n")
                if not line:
                    continue
                label, length_s, _seq = line.split("\t", 2)
                expected[label] = int(length_s)

        with h5py.File(ph5, "r") as h:
            if "scalar" not in h:
                raise RuntimeError(f"{ph5}: missing group 'scalar'")
            g = h["scalar"]
            missing = []
            badlen = []
            for label, exp_len in expected.items():
                if label not in g:
                    missing.append(label)
                    continue
                ds = g[label]
                got_len = int(ds.shape[0])
                if got_len != exp_len:
                    badlen.append((label, exp_len, got_len))

        if missing:
            raise RuntimeError(f"Embedding validation failed for shard {i}: missing {len(missing)} labels (e.g. {missing[:3]})")
        if badlen:
            raise RuntimeError(f"Embedding validation failed for shard {i}: {len(badlen)} length mismatches (e.g. {badlen[:3]})")


def run_esm_worker(
    shard_tsv: Path,
    out_h5: Path,
    report_json: Path,
    done_sentinel: Path,
    device: str,
    toks_per_batch: int,
    scalar_dtype: str,
) -> None:
    """
    Worker mode (called via --esm-worker). Loads ESM once, embeds shard, writes scalar arrays to HDF5.
    """
    t0 = perf_counter()

    out_h5.parent.mkdir(parents=True, exist_ok=True)
    report_json.parent.mkdir(parents=True, exist_ok=True)
    done_sentinel.parent.mkdir(parents=True, exist_ok=True)

    # Convert to FASTA
    fasta_path = out_h5.with_suffix(".fasta")
    n_records = shard_tsv_to_fasta(shard_tsv, fasta_path)

    # Load ESM once
    model, alphabet = pretrained.load_model_and_alphabet(ESM_MODEL)
    model.eval()

    if device.startswith("cuda") and torch.cuda.is_available():
        model = model.cuda()

    # Prepare dataset/loader
    dataset = FastaBatchedDataset.from_file(str(fasta_path))
    batches = dataset.get_batch_indices(toks_per_batch, extra_toks_per_seq=1)
    loader = torch.utils.data.DataLoader(
        dataset,
        collate_fn=alphabet.get_batch_converter(TRUNCATION_SEQ_LENGTH),
        batch_sampler=batches,
    )

    repr_layers = [(i + model.num_layers + 1) % (model.num_layers + 1) for i in REPR_LAYERS]
    layer = REPR_LAYERS[0]

    # dtype
    if scalar_dtype.lower() not in ("float16", "float32"):
        raise ValueError(f"scalar_dtype must be float16 or float32, got {scalar_dtype}")
    np_dtype = "float16" if scalar_dtype.lower() == "float16" else "float32"

    total_len = 0

    # Write HDF5 incrementally
    with h5py.File(out_h5, "w") as h:
        h.attrs["esm_model"] = ESM_MODEL
        h.attrs["repr_layer"] = int(layer)
        h.attrs["scalar_def"] = "mean_over_embedding_dim"
        h.attrs["truncation_seq_length"] = int(TRUNCATION_SEQ_LENGTH)
        h.attrs["toks_per_batch"] = int(toks_per_batch)
        h.attrs["dtype"] = np_dtype

        g = h.create_group("scalar")

        with torch.no_grad():
            for labels, strs, toks in loader:
                if device.startswith("cuda") and torch.cuda.is_available():
                    toks = toks.cuda(non_blocking=True)

                out = model(toks, repr_layers=repr_layers, return_contacts=False)
                reps = out["representations"][repr_layers[0]]  # [B, T, D]

                for i, label in enumerate(labels):
                    seq_len = len(strs[i])
                    trunc = min(TRUNCATION_SEQ_LENGTH, seq_len)

                    # token positions 1..trunc (skip BOS)
                    # reps_i: [trunc, D]
                    reps_i = reps[i, 1 : trunc + 1].detach()

                    # scalar per residue: mean over embedding dim -> [trunc]
                    scalar = reps_i.mean(dim=1)

                    if np_dtype == "float16":
                        scalar = scalar.to(dtype=torch.float16)
                    else:
                        scalar = scalar.to(dtype=torch.float32)

                    arr = scalar.cpu().numpy()
                    total_len += int(arr.shape[0])

                    # Use fast compression (lzf) and chunking
                    g.create_dataset(
                        name=str(label),
                        data=arr,
                        compression="lzf",
                        chunks=True,
                    )

    t1 = perf_counter()
    report = {
        "shard_tsv": str(shard_tsv),
        "out_h5": str(out_h5),
        "n_records": int(n_records),
        "total_residues": int(total_len),
        "wall_s": float(t1 - t0),
        "device": device,
        "toks_per_batch": int(toks_per_batch),
        "scalar_dtype": np_dtype,
        "esm_model": ESM_MODEL,
        "repr_layer": int(layer),
    }
    with open(report_json, "w") as f:
        json.dump(report, f, indent=2)

    # Sentinel indicates success
    done_sentinel.write_text("ok\n")


def run_sharded_embeddings_subprocess(
    embeddings_dir: Path,
    n_gpus: int,
    toks_per_batch: int,
    scalar_dtype: str,
    python_exe: str,
    script_path: Path,
    label_to_shard: Dict[str, int],
) -> Tuple[List[Path], float]:
    """
    Launch N embedding workers as subprocesses (one per GPU).
    Returns (part_h5_paths, esm_walltime_s).
    """
    part_h5s: List[Path] = []
    shard_tsvs: List[Path] = []
    reports: List[Path] = []
    sentinels: List[Path] = []

    for i in range(n_gpus):
        shard_tsv = embeddings_dir / f"shard{i}.tsv"
        out_h5 = embeddings_dir / f"emb_part{i}.h5"
        report_json = embeddings_dir / f"emb_part{i}.report.json"
        done = embeddings_dir / f"embed_done.part{i}"
        shard_tsvs.append(shard_tsv)
        part_h5s.append(out_h5)
        reports.append(report_json)
        sentinels.append(done)

        if done.exists():
            done.unlink()
        if report_json.exists():
            report_json.unlink()

    # Save label->shard map for injection routing
    with open(embeddings_dir / "label_to_shard.json", "w") as f:
        json.dump(label_to_shard, f, indent=2)

    procs: List[subprocess.Popen] = []
    t0 = perf_counter()

    for i in range(n_gpus):
        env = os.environ.copy()
        env["CUDA_VISIBLE_DEVICES"] = str(i)
        # Honor optional caching (recommended on node-local SSD)
        # Users can set TORCH_HOME / ESM cache via env before calling the script.

        args = [
            python_exe,
            str(script_path),
            "--esm-worker",
            "--shard-tsv", str(shard_tsvs[i]),
            "--out-h5", str(part_h5s[i]),
            "--report-json", str(reports[i]),
            "--done-sentinel", str(sentinels[i]),
            "--device", "cuda",
            "--esm-toks-per-batch", str(toks_per_batch),
            "--esm-scalar-dtype", str(scalar_dtype),
        ]
        procs.append(subprocess.Popen(args, env=env))

    # Wait
    rc = []
    for p in procs:
        rc.append(p.wait())

    t1 = perf_counter()

    # Check return codes
    bad = [(i, r) for i, r in enumerate(rc) if r != 0]
    if bad:
        raise RuntimeError(f"One or more ESM workers failed: {bad}")

    # Check sentinels exist
    missing_sentinels = [str(s) for s in sentinels if not s.is_file()]
    if missing_sentinels:
        raise RuntimeError(f"Missing ESM done sentinels: {missing_sentinels}")

    # Validate parts
    validate_embedding_parts(shard_tsvs, part_h5s)

    # Summarize reports (optional but useful)
    worker_reports = []
    for r in reports:
        if r.is_file():
            worker_reports.append(json.loads(r.read_text()))
    with open(embeddings_dir / "embed_report.json", "w") as f:
        json.dump(
            {
                "n_gpus": n_gpus,
                "toks_per_batch": toks_per_batch,
                "scalar_dtype": scalar_dtype,
                "workers": worker_reports,
                "wall_s": float(t1 - t0),
                "critical_path_s": float(max((wr.get("wall_s", 0.0) for wr in worker_reports), default=(t1 - t0))),
            },
            f,
            indent=2,
        )

    # For pipeline timing: critical path is max worker walltime if available, else coordinator walltime
    crit = None
    if worker_reports:
        crit = max((wr.get("wall_s", 0.0) for wr in worker_reports), default=None)
    esm_wall = float(crit) if crit is not None else float(t1 - t0)

    return part_h5s, esm_wall


# ----------------------------
# Embedding injection (from sharded HDF5 parts)
# ----------------------------
def inject_embeddings_from_parts(
    graph_hdf5: Path,
    part_h5s: List[Path],
    label_to_shard_json: Path,
) -> None:
    """
    Inject scalar-per-residue embedding feature into each mol in graph HDF5.

    Expected embedding datasets:
      part_h5s[k]: group /scalar/<mol>.<chain> => 1D array length L

    Assumes residues in chain A/B are renumbered from 1..N so resid-1 indexes ESM positions.
    """
    if not label_to_shard_json.is_file():
        raise FileNotFoundError(f"Missing label_to_shard map: {label_to_shard_json}")
    label_to_shard = json.loads(label_to_shard_json.read_text())

    # Open all embedding parts once
    part_handles = [h5py.File(p, "r") for p in part_h5s]
    try:
        scalar_groups = []
        for h in part_handles:
            if "scalar" not in h:
                raise RuntimeError(f"Embedding part missing /scalar group: {h.filename}")
            scalar_groups.append(h["scalar"])

        missing_labels = 0
        oob = 0

        with h5py.File(graph_hdf5, "r+") as f:
            for mol in f.keys():
                residues = f[mol]["nodes"][()]  # typically array of [chain, resid, ...]
                emb = torch.zeros((len(residues), 1), dtype=torch.float32)

                # Cache loaded scalar arrays per (mol, chain)
                cache_scalar: Dict[str, List[float]] = {}

                for i, res in enumerate(residues):
                    chain = res[0].decode() if isinstance(res[0], (bytes, bytearray)) else str(res[0])
                    resid = int(res[1].decode()) if isinstance(res[1], (bytes, bytearray)) else int(res[1])

                    label = f"{mol}.{chain}"
                    shard = label_to_shard.get(label, None)
                    if shard is None or shard < 0 or shard >= len(scalar_groups):
                        missing_labels += 1
                        continue

                    if label not in cache_scalar:
                        g = scalar_groups[shard]
                        if label not in g:
                            missing_labels += 1
                            continue
                        cache_scalar[label] = g[label][()]  # numpy array 1D

                    arr = cache_scalar[label]
                    j = resid - 1
                    if 0 <= j < len(arr):
                        emb[i, 0] = float(arr[j])
                    else:
                        oob += 1
                        # leave zero

                grp = f[mol].require_group("node_data")
                if "embedding" in grp:
                    del grp["embedding"]
                grp.create_dataset("embedding", data=emb.numpy())

        if missing_labels > 0:
            log.warning(f"[EMB] Missing labels during injection: {missing_labels}")
        if oob > 0:
            log.warning(f"[EMB] Residue indices out-of-bounds during injection: {oob}")

    finally:
        for h in part_handles:
            try:
                h.close()
            except Exception:
                pass


# ----------------------------
# Clustering + prediction
# ----------------------------
def cluster_mcl(graph_hdf5: Path) -> None:
    dataset = HDF5DataSet(name="EvalSet", root="./", database=str(graph_hdf5))
    PreCluster(dataset, method="mcl")


def predict(
    graph_hdf5: Path,
    model_path: Path,
    out_pred_hdf5: Path,
    device: str,
    dl_workers: int,
    batch_size: int,
    num_cores: int,
) -> None:
    # Clamp dl workers to something sane on head nodes / small systems
    if dl_workers < 0:
        dl_workers = 0
    if dl_workers > num_cores:
        dl_workers = num_cores

    net = NeuralNet(
        database=str(graph_hdf5),
        Net=egnn,
        node_feature=NODE_FEATURES,
        edge_feature=EDGE_FEATURES,
        target=None,
        task="reg",
        batch_size=batch_size,
        num_workers=dl_workers,
        device_name=device,
        shuffle=False,
        pretrained_model=str(model_path),
        cluster_nodes="mcl",
    )

    net.predict(database_test=str(graph_hdf5), hdf5=str(out_pred_hdf5))


# ----------------------------
# Main pipeline
# ----------------------------
def process_one_pdb_no_esm(
    pdb_path: Path,
    heavy: str,
    light: str,
    antigen: str,
    processed_dir: Path,
    fasta_dir: Path,
    timings: Dict[str, float],
) -> Tuple[Path, Optional[SeqRecord], Optional[SeqRecord]]:
    """
    Process a single PDB (single MODEL file):
      - create merged processed PDB with A/B chains
      - write HL fasta for annotation
      - return two SeqRecord objects for batch embedding (mol.A and mol.B)
    Returns: (merged_pdb_path, recA, recB)
    """
    stem = pdb_path.stem
    merged_pdb = processed_dir / f"{stem}.pdb"

    t0 = perf_counter()
    seqH, seqL, seqAg = build_merged_structure(
        pdb_path=pdb_path,
        heavy_chain_id=heavy,
        light_chain_id=light,
        antigen_chain_id=antigen,
        out_pdb=merged_pdb,
    )
    _ = write_hl_fasta(stem, fasta_dir, seqH, seqL)
    t1 = perf_counter()
    timings["prep_s"] += (t1 - t0)

    seqA = (seqH or "") + (seqL or "")
    seqB = (seqAg or "")

    recA = SeqRecord(label=f"{stem}.A", mol=stem, chain="A", length=len(seqA), sequence=seqA) if seqA else None
    recB = SeqRecord(label=f"{stem}.B", mol=stem, chain="B", length=len(seqB), sequence=seqB) if seqB else None

    return merged_pdb, recA, recB


def run_batched_inference(
    pdb_folder: Path,
    out_root: Path,
    model_path: Path,
    heavy: str,
    light: str,
    antigen: str,
    antigen_chainid_for_graph: str,
    num_cores: int,
    graph_batch_size: int,
    dl_workers: int,
    batch_size: int,
    device: str,
    tmp_base: Optional[Path] = None,
    keep_intermediates: bool = False,
    esm_gpus: int = 4,
    esm_toks_per_batch: int = DEFAULT_TOKS_PER_BATCH,
    esm_scalar_dtype: str = "float16",
) -> List[Path]:
    """
    End-to-end:
      - split ensembles → per-model pdbs
      - per batch: preprocess + manifest, sharded embeddings (N GPUs), annotate, graphs, inject, cluster, predict
    """
    pdb_folder = pdb_folder.resolve()
    out_root = out_root.resolve()
    safe_mkdir(out_root)

    # Discover inputs
    pdbs_in = sorted(pdb_folder.glob("*.pdb"))
    if not pdbs_in:
        raise FileNotFoundError(f"No PDBs found in {pdb_folder}")

    # Expand ensembles to per-model pdbs into a staging area
    staging = out_root / "staging_models"
    safe_mkdir(staging)

    expanded: List[Path] = []
    for pdb in pdbs_in:
        out_dir = staging / pdb.stem
        expanded.extend(split_models(pdb, out_dir))

    log.info(f"Found {len(pdbs_in)} input PDBs → expanded to {len(expanded)} model PDBs")

    batches = list(chunk_list(expanded, graph_batch_size))
    log.info(f"Batches: {len(batches)} (size ~{graph_batch_size})")

    pred_files: List[Path] = []

    # For launching workers
    python_exe = sys.executable
    script_path = Path(__file__).resolve()

    for bi, batch in enumerate(batches):
        tag = f"batch{bi:04d}"
        log.info(f"=== Processing {tag}: n={len(batch)} ===")

        tB0 = perf_counter()

        # Per-batch workspace
        batch_root = out_root / tag
        processed_dir = safe_mkdir(batch_root / "processed")
        fasta_dir = safe_mkdir(batch_root / "fastas")
        emb_dir = safe_mkdir(batch_root / "embeddings")
        anno_dir = safe_mkdir(batch_root / "annotations")

        # Per-batch timings
        timings: Dict[str, float] = {
            "prep_s": 0.0,
            "esm_s": 0.0,
            "graphs_s": 0.0,
            "infer_s": 0.0,
        }

        # Preprocess and collect sequences
        records: List[SeqRecord] = []
        ok_models = 0
        skipped = 0

        for pdb_model in batch:
            try:
                _merged, recA, recB = process_one_pdb_no_esm(
                    pdb_path=pdb_model,
                    heavy=heavy,
                    light=light,
                    antigen=antigen,
                    processed_dir=processed_dir,
                    fasta_dir=fasta_dir,
                    timings=timings,
                )
                if recA:
                    records.append(recA)
                if recB:
                    records.append(recB)
                ok_models += 1
            except Exception as e:
                skipped += 1
                log.warning(f"[SKIP] {pdb_model.name}: {e}")

        log.info(f"[BATCH] {tag} models ok={ok_models} skipped={skipped}")
        log.info(f"[TIME] {tag} PREP: {timings['prep_s']:.3f}s")

        # Manifest + sharding
        manifest_tsv = emb_dir / "manifest.tsv"
        write_manifest_tsv(records, manifest_tsv)

        shards, label_to_shard = shard_records_balanced(records, n_shards=max(1, int(esm_gpus)))
        shard_tsvs: List[Path] = []
        for i, shard_recs in enumerate(shards):
            stsv = emb_dir / f"shard{i}.tsv"
            write_shard_tsv(shard_recs, stsv)
            shard_tsvs.append(stsv)

        # Embedding stage (sharded across GPUs)
        if esm_gpus < 1:
            raise ValueError("--esm-gpus must be >= 1")

        tE0 = perf_counter()
        part_h5s, esm_crit_wall = run_sharded_embeddings_subprocess(
            embeddings_dir=emb_dir,
            n_gpus=esm_gpus,
            toks_per_batch=esm_toks_per_batch,
            scalar_dtype=esm_scalar_dtype,
            python_exe=python_exe,
            script_path=script_path,
            label_to_shard=label_to_shard,
        )
        tE1 = perf_counter()
        # Use critical path time if available; else coordinator walltime
        timings["esm_s"] += float(esm_crit_wall)
        log.info(f"[TIME] {tag} ESM (crit): {timings['esm_s']:.3f}s  (coord wall {tE1 - tE0:.3f}s)")

        # Annotate (uses *_HL.fasta)
        annotate_folder_one_by_one_mp(
            processed_dir,
            fasta_dir,
            output_dir=str(anno_dir),
            n_cores=num_cores,
            antigen_chainid=antigen_chainid_for_graph,  # usually "B" for merged PDB
        )
        region_json = anno_dir / "annotations_cdrs.json"
        correct_region_json(region_json)

        # Graph gen
        tG0 = perf_counter()
        graph_hdf5 = out_root / f"graphs_{tag}.hdf5"
        gen_graphs(
            pdb_dir=processed_dir,
            outfile=graph_hdf5,
            region_json=region_json,
            n_cores=num_cores,
            antigen_chainid=antigen_chainid_for_graph,
            tmp_base=tmp_base,
        )

        # Inject embeddings from HDF5 parts
        inject_embeddings_from_parts(
            graph_hdf5=graph_hdf5,
            part_h5s=part_h5s,
            label_to_shard_json=emb_dir / "label_to_shard.json",
        )

        # Cluster
        cluster_mcl(graph_hdf5)
        tG1 = perf_counter()
        timings["graphs_s"] += (tG1 - tG0)
        log.info(f"[TIME] {tag} GRAPHS+INJECT+CLUSTER: {timings['graphs_s']:.3f}s")

        # Predict
        tI0 = perf_counter()
        pred_hdf5 = out_root / f"pred_{tag}.hdf5"
        predict(
            graph_hdf5=graph_hdf5,
            model_path=model_path,
            out_pred_hdf5=pred_hdf5,
            device=device,
            dl_workers=dl_workers,
            batch_size=batch_size,
            num_cores=num_cores,
        )
        tI1 = perf_counter()
        timings["infer_s"] += (tI1 - tI0)
        log.info(f"[TIME] {tag} INFER: {timings['infer_s']:.3f}s")

        pred_files.append(pred_hdf5)
        log.info(f"[DONE] {tag} → {pred_hdf5}")

        if not keep_intermediates:
            shutil.rmtree(batch_root, ignore_errors=True)

        tB1 = perf_counter()
        log.info(f"[TIME] {tag} TOTAL: {(tB1 - tB0):.3f}s")

    if not keep_intermediates:
        shutil.rmtree(staging, ignore_errors=True)

    return pred_files


# ----------------------------
# CLI
# ----------------------------
def main():
    ap = argparse.ArgumentParser()

    # Hidden worker mode
    ap.add_argument("--esm-worker", action="store_true", help=argparse.SUPPRESS)
    ap.add_argument("--shard-tsv", default=None, help=argparse.SUPPRESS)
    ap.add_argument("--out-h5", default=None, help=argparse.SUPPRESS)
    ap.add_argument("--report-json", default=None, help=argparse.SUPPRESS)
    ap.add_argument("--done-sentinel", default=None, help=argparse.SUPPRESS)

    # Common ESM knobs (also used in worker mode)
    ap.add_argument("--esm-toks-per-batch", type=int, default=DEFAULT_TOKS_PER_BATCH,
                    help=f"ESM token budget per step (default {DEFAULT_TOKS_PER_BATCH}).")
    ap.add_argument("--esm-scalar-dtype", default=os.environ.get("ESM_SCALAR_DTYPE", "float16"),
                    help="Scalar embedding dtype: float16 or float32 (default float16).")

    # Main pipeline args
    ap.add_argument("--pdb-folder", required=False, help="Folder containing input *.pdb")
    ap.add_argument("--out", required=False, help="Output folder for batch graphs/preds")
    ap.add_argument("--model-path", required=False, help="Path to pretrained DeepRank-Ab .pth.tar")
    ap.add_argument("--heavy", required=False, help="Heavy chain id in input PDB (e.g. H)")
    ap.add_argument("--light", default="-", help="Light chain id in input PDB (e.g. L) or '-' for VHH")
    ap.add_argument("--antigen", required=False, help="Antigen chain id in input PDB (e.g. T)")
    ap.add_argument("--antigen-chainid-for-graph", default="B",
                    help="Antigen chain id in MERGED processed PDB for graph features (default B)")
    ap.add_argument("--num-cores", type=int, default=int(os.environ.get("NUM_CORES", "32")))
    ap.add_argument("--graph-batch-size", type=int, default=int(os.environ.get("GRAPH_BATCH_SIZE", "500")))
    ap.add_argument("--dl-workers", type=int, default=int(os.environ.get("DL_WORKERS", "8")),
                    help="PyTorch DataLoader workers for inference")
    ap.add_argument("--batch-size", type=int, default=int(os.environ.get("BATCH_SIZE", "64")),
                    help="Inference batch size")
    ap.add_argument("--device", default=("cuda" if torch.cuda.is_available() else "cpu"))
    ap.add_argument("--tmp-base", default=os.environ.get("TMPDIR", None),
                    help="Base temp dir (e.g. local SSD TMPDIR).")
    ap.add_argument("--keep-intermediates", action="store_true", help="Keep per-batch processed/fastas/embeddings.")

    # New ESM sharding control
    ap.add_argument("--esm-gpus", type=int, default=int(os.environ.get("ESM_GPUS", "4")),
                    help="Number of GPUs to shard ESM embeddings across (default 4).")

    args = ap.parse_args()

    # Worker mode
    if args.esm_worker:
        if not (args.shard_tsv and args.out_h5 and args.report_json and args.done_sentinel):
            raise SystemExit("esm-worker mode requires --shard-tsv, --out-h5, --report-json, --done-sentinel")
        run_esm_worker(
            shard_tsv=Path(args.shard_tsv),
            out_h5=Path(args.out_h5),
            report_json=Path(args.report_json),
            done_sentinel=Path(args.done_sentinel),
            device=args.device,
            toks_per_batch=int(args.esm_toks_per_batch),
            scalar_dtype=str(args.esm_scalar_dtype),
        )
        return

    # Main mode
    if not (args.pdb_folder and args.out and args.model_path and args.heavy and args.antigen):
        raise SystemExit("Missing required args: --pdb-folder, --out, --model-path, --heavy, --antigen")

    pdb_folder = Path(args.pdb_folder)
    out_root = Path(args.out)
    model_path = Path(args.model_path)

    tmp_base = Path(args.tmp_base) if args.tmp_base else None

    preds = run_batched_inference(
        pdb_folder=pdb_folder,
        out_root=out_root,
        model_path=model_path,
        heavy=args.heavy,
        light=args.light,
        antigen=args.antigen,
        antigen_chainid_for_graph=args.antigen_chainid_for_graph,
        num_cores=args.num_cores,
        graph_batch_size=args.graph_batch_size,
        dl_workers=args.dl_workers,
        batch_size=args.batch_size,
        device=args.device,
        tmp_base=tmp_base,
        keep_intermediates=args.keep_intermediates,
        esm_gpus=int(args.esm_gpus),
        esm_toks_per_batch=int(args.esm_toks_per_batch),
        esm_scalar_dtype=str(args.esm_scalar_dtype),
    )

    log.info("All batches complete.")
    log.info("Prediction files:")
    for p in preds:
        log.info(f"  {p}")


if __name__ == "__main__":
    main()

